

### 使用线程池

```java
/** 
* 描述：     用固定线程数的线程池执行10000个任务 
*/ 
public class ThreadPoolDemo { 
 
    public static void main(String[] args) { 
        
        ExecutorService service = Executors.newFixedThreadPool(5);
        
        for (int i = 0; i < 10000; i++) { 
            service.execute(new Task());
        } 
        
    	System.out.println(Thread.currentThread().getName());
    } 
 
    static class Task implements Runnable { 
 
        public void run() { 
            System.out.println("Thread Name: " + Thread.currentThread().getName());
        } 
        
    } 
}

```

首先创建了一个线程池，线程池中有 5 个线程，然后线程池将 10000 个任务分配给这 5 个线程，这 5 个线程反复领取任务并执行，直到所有任务执行完毕 。



#### 线程池的参数

线程池主要有 6 个参数:

| 参数名                     | 含义                   |
| -------------------------- | ---------------------- |
| `corePoolSize`             | 核心线程数             |
| `maximumPoolSize`          | 最大线程数             |
| `keepAliveTime` + 时间单位 | 空闲线程的存活时间     |
| `workQueue`                | 用于存放任务的队列     |
| `ThreadFactory`            | 线程工厂用来创建新线程 |
| `RejectedExecutionHandler` | 处理被拒绝的任务       |



```java
public class Executors {

    public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>());
    }
    
}

public class ThreadPoolExecutor extends AbstractExecutorService {
    
    public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue) {
        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
             Executors.defaultThreadFactory(), defaultHandler);
    }
    
    public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        。。。
    }
}
```



####  线程创建的时机



<img src="./img/线程池的主要处理流程.PNG" style="zoom:80%;" />



接下来，我们来具体看下这两个参数所代表的含义，以及线程池中创建线程的时机。如上图所示，当提交任务后，线程池首先会检查当前线程数，如果此时线程数小于核心线程数，比如最开始线程数量为 0，则新建线程并执行任务，随着任务的不断增加，线程数会逐渐增加并达到核心线程数，此时如果仍有任务被不断提交，就会被放入` workQueue` 任务队列中，等待核心线程执行完当前任务后重新从 `workQueue` 中提取正在等待被执行的任务。

此时，假设我们的任务特别的多，已经达到了 `workQueue `的容量上限，这时线程池就会启动后备力量，也就是 `maximumPoolSize` 最大线程数，线程池会在` corePoolSize` 核心线程数的基础上继续创建线程来执行任务，假设任务被不断提交，线程池会持续创建线程直到线程数达到 `maximumPoolSize` 最大线程数，如果依然有任务被提交，这就超过了线程池的最大处理能力，这个时候线程池就会拒绝这些任务，我们可以看到实际上任务进来之后，线程池会逐一判断` corePoolSize、workQueue、maximumPoolSize`，如果依然不能满足需求，则会拒绝任务。

#####  `corePoolSize` 与 `maximumPoolSize   `

通过上面的流程图，我们了解了 `corePoolSize `和` maximumPoolSize` 的具体含义，`corePoolSize` 指的是核心线程数，线程池初始化时线程数默认为 0，当有新的任务提交后，会创建新线程执行任务，如果不做特殊设置，此后线程数通常不会再小于` corePoolSize` ，因为它们是核心线程，即便未来可能没有可执行的任务也不会被销毁。随着任务量的增加，在任务队列满了之后，线程池会进一步创建新线程，最多可以达到 `maximumPoolSize` 来应对任务多的场景，如果未来线程有空闲，大于 `corePoolSize` 的线程会被合理回收。所以正常情况下，线程池中的线程数量会处在` corePoolSize` 与` maximumPoolSize `的闭区间内。


我们可以把 `corePoolSize` 与 `maximumPoolSize `比喻成长工与临时工，通常古代一个大户人家会有几个固定的长工，负责日常的工作，而大户人家起初肯定也是从零开始雇佣长工的。假如长工数量被老爷设定为 5 人，也就对应了` corePoolSize`，不管这 5 个长工是忙碌还是空闲，都会一直在大户人家待着，可到了农忙或春节，长工的人手显然就不够用了，这时就需要雇佣更多的临时工，这些临时工就相当于在 `corePoolSize `的基础上继续创建新线程，但临时工也是有上限的，也就对应了` maximumPoolSize`，随着农忙或春节结束，老爷考虑到人工成本便会解约掉这些临时工，家里工人数量便会从` maximumPoolSize` 降到` corePoolSize`，所以老爷家的工人数量会一致保持在` corePoolSize` 和` maximumPoolSize` 的区间。



线程池的`corePoolSize` 为 5，`maximumPoolSize` 为 10，任务队列容量为 100，随着任务被提交，我们的线程数量会从 0 慢慢增长到 5，然后就不再增长了，新的任务会被放入队列中，直到队列被塞满，然后在 `corePoolSize `的基础上继续创建新线程来执行队列中的任务，线程会逐渐增加到 `maximumPoolSize`， 然后线程数不再增加，如果此时仍有任务被不断提交，线程池就会拒绝任务。随着队列中任务被执行完，被创建的 10 个线程现在无事可做了，这时线程池会根据` keepAliveTime `参数来销毁线程，已达到减少内存占用的目的。



#### 线程池的几个特点

1. 线程池希望保持较少的线程数，并且只有在负载变得很大时才增加线程。
2. 线程池只有在任务队列填满时才创建多于` corePoolSize `的线程，如果使用的是无界队列（例如` LinkedBlockingQueue`），那么由于队列不会满，所以线程数不会超过` corePoolSize`。
3. 通过设置` corePoolSize `和` maximumPoolSize` 为相同的值，就可以创建固定大小的线程池。
4. 通过设置 `maximumPoolSize `为很高的值，例如` Integer.MAX_VALUE`，就可以允许线程池创建任意多的线程。



#### `keepAliveTime`+时间单位     


第三个参数是 `keepAliveTime` + 时间单位，当线程池中线程数量多于核心线程数时，而此时又没有任务可做，线程池就会检测线程的 `keepAliveTime`，如果超过规定的时间，无事可做的线程就会被销毁，以便减少内存的占用和资源消耗。如果后期任务又多了起来，线程池也会根据规则重新创建线程，所以这是一个可伸缩的过程，比较灵活，我们也可以用 `setKeepAliveTime` 方法动态改变 `keepAliveTime` 的参数值。



 ####  `ThreadFactory `

第四个参数是 `ThreadFactory`，`ThreadFactory `实际上是一个线程工厂，它的作用是生产线程以便执行任务。我们可以选择使用默认的线程工厂，创建的线程都会在同一个线程组，并拥有一样的优先级，且都不是守护线程，我们也可以选择自己定制线程工厂，以方便给线程自定义命名，不同的线程池内的线程通常会根据具体业务来定制不同的线程名。

#### `workQueue` 和 `Handler`     


最后两个参数是 `workQueue` 和 `Handler`，它们分别对应阻塞队列和任务拒绝策略 。



###  线程池的拒绝策略

####  拒绝时机

新建线程池时可以指定它的任务拒绝策略，例如：

```java
newThreadPoolExecutor(5, 10, 5, TimeUnit.SECONDS, new LinkedBlockingQueue<>(),
   new ThreadPoolExecutor.DiscardOldestPolicy());
```

以便在必要的时候按照我们的策略来拒绝任务，那么拒绝任务的时机是什么呢？线程池会在以下两种情况下会拒绝新提交的任务。

1. 第一种情况是当我们调用 shutdown 等方法关闭线程池后，即便此时可能线程池内部依然有没执行完的任务正在执行，但是由于线程池已经关闭，此时如果再向线程池内提交任务，就会遭到拒绝。
2. 第二种情况是线程池没有能力继续处理新提交的任务，也就是工作已经非常饱和的时候。

第二种情况， 就是由于工作饱和导致的拒绝。比如新建一个线程池，使用容量上限为 10 的 `ArrayBlockingQueue` 作为任务队列，并且指定线程池的核心线程数为 5，最大线程数为 10，假设此时有 20 个耗时任务被提交，在这种情况下，线程池会首先创建核心数量的线程，也就是5个线程来执行任务，然后往队列里去放任务，队列的 10 个容量被放满了之后，会继续创建新线程，直到达到最大线程数 10。此时线程池中一共有 20 个任务，其中 10 个任务正在被 10 个线程执行，还有 10 个任务在任务队列中等待，而且由于线程池的最大线程数量就是 10，所以已经不能再增加更多的线程来帮忙处理任务了，这就意味着此时线程池工作饱和，这个时候再提交新任务时就会被拒绝。

#### 拒绝策略

Java 在 `ThreadPoolExecutor` 类中为我们提供了 4 种默认的拒绝策略来应对不同的场景，都实现了 `RejectedExecutionHandler` 接口，如图所示：

<img src="./img/拒绝策略.png" style="zoom:75%;" />



1. 第一种拒绝策略是 `AbortPolicy`，这种拒绝策略在拒绝任务时，会直接抛出一个类型为 `RejectedExecutionException` 的 `RuntimeException`，让你感知到任务被拒绝了，于是你便可以根据业务逻辑选择重试或者放弃提交等策略。
2. 第二种拒绝策略是 `DiscardPolicy`，这种拒绝策略正如它的名字所描述的一样，当新任务被提交后直接被丢弃掉，也不会给你任何的通知，相对而言存在一定的风险，因为我们提交的时候根本不知道这个任务会被丢弃，可能造成数据丢失。
3. 第三种拒绝策略是 `DiscardOldestPolicy`，如果线程池没被关闭且没有能力执行，则会丢弃任务队列中的头结点，通常是存活时间最长的任务，这种策略与第二种不同之处在于它丢弃的不是最新提交的，而是队列中存活时间最长的，这样就可以腾出空间给新提交的任务，但同理它也存在一定的数据丢失风险。
4. 第四种拒绝策略是 `CallerRunsPolicy`，相对而言它就比较完善了，当有新任务提交后，如果线程池没被关闭且没有能力执行，则把这个任务交于提交任务的线程执行，也就是谁提交任务，谁就负责执行任务。这样做主要有两点好处。
   1. 第一点新提交的任务不会被丢弃，这样也就不会造成业务损失。
   2. 第二点好处是，由于谁提交任务谁就要负责执行任务，这样提交任务的线程就得负责执行任务，而执行任务又是比较耗时的，在这段期间，提交任务的线程被占用，也就不会再提交新的任务，减缓了任务提交的速度，相当于是一个负反馈。在此期间，线程池中的线程也可以充分利用这段时间来执行掉一部分任务，腾出一定的空间，相当于是给了线程池一定的缓冲期。



### 常见的线程池

#### `FixedThreadPool`

第一种线程池叫作 `FixedThreadPool`，它的核心线程数和最大线程数是一样的，所以可以把它看作是固定线程数的线程池，它的特点是线程池中的线程数除了初始阶段需要从 0 开始增加外，之后的线程数量就是固定的，就算任务数超过线程数，线程池也不会再创建更多的线程来处理任务，而是会把超出线程处理能力的任务放到任务队列中进行等待。而且就算任务队列满了，到了本该继续增加线程数的时候，由于它的最大线程数和核心线程数是一样的，所以也无法再增加新的线程了。



#### `CachedThreadPool`

第二种线程池是 `CachedThreadPool`，可以称作可缓存线程池，它的特点在于线程数是几乎可以无限增加的（实际最大可以达到 `Integer.MAX_VALUE`，为 2^31-1，这个数非常大，所以基本不可能达到），而当线程闲置时还可以对线程进行回收。也就是说该线程池的线程数量不是固定不变的，当然它也有一个用于存储提交任务的队列，但这个队列是 `SynchronousQueue`，队列的容量为0，实际不存储任何任务，它只负责对任务进行中转和传递，所以效率比较高。

当我们提交一个任务后，线程池会判断已创建的线程中是否有空闲线程，如果有空闲线程则将任务直接指派给空闲线程，如果没有空闲线程，则新建线程去执行任务，这样就做到了动态地新增线程。让我们举个例子，如下方代码所示。

```java
ExecutorService service = Executors.newCachedThreadPool();
    for (int i = 0; i < 1000; i++) { 
        service.execute(new Task() { 
    });
 }
```

使用 for 循环提交 1000 个任务给 `CachedThreadPool`，假设这些任务处理的时间非常长，会发生什么情况呢？因为 for 循环提交任务的操作是非常快的，但执行任务却比较耗时，就可能导致 1000 个任务都提交完了但第一个任务还没有被执行完，所以此时 `CachedThreadPool` 就可以动态的伸缩线程数量，随着任务的提交，不停地创建 1000 个线程来执行任务，而当任务执行完之后，假设没有新的任务了，那么大量的闲置线程又会造成内存资源的浪费，这时线程池就会检测线程在 60 秒内有没有可执行任务，如果没有就会被销毁，最终线程数量会减为 0。



 ####  `ScheduledThreadPool`

第三个线程池是 `ScheduledThreadPool`，它支持定时或周期性执行任务。比如每隔 10 秒钟执行一次任务，而实现这种功能的方法主要有 3 种，如代码所示：

```java
ScheduledExecutorService service = Executors.newScheduledThreadPool(10);
 
service.schedule(new Task(), 10, TimeUnit.SECONDS);
 
service.scheduleAtFixedRate(new Task(), 10, 10, TimeUnit.SECONDS);
 
service.scheduleWithFixedDelay(new Task(), 10, 10, TimeUnit.SECONDS);

```

那么这 3 种方法有什么区别呢？

第一种方法 schedule 比较简单，表示延迟指定时间后执行一次任务，如果代码中设置参数为 10 秒，也就是 10 秒后执行一次任务后就结束。

第二种方法 `scheduleAtFixedRate` 表示以固定的频率执行任务，它的第二个参数` initialDelay `表示第一次延时时间，第三个参数 period 表示周期，也就是第一次延时后每次延时多长时间执行一次任务。

第三种方法` scheduleWithFixedDelay `与第二种方法类似，也是周期执行任务，区别在于对周期的定义，之前的 `scheduleAtFixedRate` 是以任务开始的时间为时间起点开始计时，时间到就开始执行第二次任务，而不管任务需要花多久执行；而 `scheduleWithFixedDelay `方法以任务结束的时间为下一次循环的时间起点开始计时。



#### `SingleThreadExecutor`

第四种线程池是 `SingleThreadExecutor`，它会使用唯一的线程去执行任务，原理和` FixedThreadPool `是一样的，只不过这里线程只有一个，如果线程在执行任务的过程中发生异常，线程池也会重新创建一个线程来执行后续的任务。这种线程池由于只有一个线程，所以非常适合用于所有任务都需要按被提交的顺序依次执行的场景，而前几种线程池不一定能够保障任务的执行顺序等于被提交的顺序，因为它们是多线程并行执行的。



####  `SingleThreadScheduledExecutor`

第五个线程池是 `SingleThreadScheduledExecutor`，它实际和第三种 `ScheduledThreadPool `线程池非常相似，它只是 `ScheduledThreadPool `的一个特例，内部只有一个线程



##### `ForkJoinPool`

`ForkJoinPool `线程池非常适合执行可以产生子任务的任务。

​		我们有一个 Task，这个 Task 可以产生三个子任务，三个子任务并行执行完毕后将结果汇总给 Result，比如说主任务需要执行非常繁重的计算任务，我们就可以把计算拆分成三个部分，这三个部分是互不影响相互独立的，这样就可以利用 CPU 的多核优势，并行计算，然后将结果进行汇总。这里面主要涉及两个步骤，第一步是拆分也就是 Fork，第二步是汇总也就是 Join，到这里你应该已经了解到 `ForkJoinPool` 线程池名字的由来了。



`ForkJoinPool `线程池有多种方法可以实现任务的分裂和汇总，其中一种用法如下方代码所示。

```java
class Fibonacci extends RecursiveTask<Integer> { 
 
    int n;
 
    public Fibonacci(int n) { 
        this.n = n;
    } 
 
    @Override
    public Integer compute() { 
        if (n <= 1) { 
            return n;
        } 
    	Fibonacci f1 = new Fibonacci(n - 1);
    	f1.fork();
   	 	Fibonacci f2 = new Fibonacci(n - 2);
    	f2.fork();
    	return f1.join() + f2.join();
    } 
 }

```

我们看到它首先继承了 `RecursiveTask`，`RecursiveTask` 类是对`ForkJoinTask` 的一个简单的包装，这时我们重写 compute() 方法，当 n<=1 时直接返回，当 n>1 就创建递归任务，也就是` f1` 和` f2`，然后我们用 fork() 方法分裂任务并分别执行，最后在 return 的时候，使用 join() 方法把结果汇总，这样就实现了任务的分裂和汇总。

```java
public static void main(String[] args) throws ExecutionException, InterruptedException { 
    ForkJoinPool forkJoinPool = new ForkJoinPool();
    for (int i = 0; i < 10; i++) { 
        ForkJoinTask task = forkJoinPool.submit(new Fibonacci(i));
        System.out.println(task.get());
    } 
 }

```



`ForkJoinPool` 线程池内部除了有一个共用的任务队列之外，每个线程还有一个对应的双端队列 `deque`，这时一旦线程中的任务被 Fork 分裂了，分裂出来的子任务放入线程自己的 `deque` 里，而不是放入公共的任务队列中。如果此时有三个子任务放入线程` t1 `的` deque `队列中，对于线程` t1 `而言获取任务的成本就降低了，可以直接在自己的任务队列中获取而不必去公共队列中争抢也不会发生阻塞（除了后面会讲到的 steal 情况外），减少了线程间的竞争和切换，是非常高效的。



我们再考虑一种情况，此时线程有多个，而线程` t1` 的任务特别繁重，分裂了数十个子任务，但是` t0`  此时却无事可做，它自己的` deque `队列为空，这时为了提高效率，`t0 `就会想办法帮助` t1 `执行任务，这就是“work-stealing”的含义。



双端队列 `deque `中，线程` t1 `获取任务的逻辑是后进先出，也就是`LIFO（Last In Frist Out）`，而线程` t0` 在`“steal”`偷线程 `t1` 的 `deque `中的任务的逻辑是先进先出，也就是`FIFO（Fast In Frist Out）`，如图所示，图中很好的描述了两个线程使用双端队列分别获取任务的情景。你可以看到，使用 “work-stealing” 算法和双端队列很好地平衡了各线程的负载。

<img src="./img/fork-join-pool.png" style="zoom:80%;" />



